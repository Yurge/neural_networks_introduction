
from sympy import symbols, diff, lambdify


# ------------------------------- 1й  вид  Регуляризации  (L2 - регуляризация) -------------------------------
# В хвост функции потерь добавляем сумму квадратов весов помноженную на константу
#  C * (w1 ** 2 + w0 ** 2)
# С - это Константа (чем больше значение, тем веса ближе к 0, например 0.0002)

# Определяем символьные переменные
w1, w0 = symbols('w1 w0')

# входные и целевые данные ТВ
x_val, y_val = [-1, 0, 1], [1, 0, -1]

# У нас простейшая НС. один аргумент на входе и по одному w1, w0, один нейрон
# Запишем функцию активации, функцию НС и Функцию Потерь
R = lambda elem: elem
F = lambda x: x * w1 + w0
C = 1							# константа
F_w = sum((R(F(x)) - y) ** 2 for x, y in zip(x_val, y_val)) + C * (w1 ** 2 + w0 ** 2)
print(F_w)

# Вычислим производные
df_w1 = diff(F_w, w1)
df_w0 = diff(F_w, w0)

# Зададим первую точку и шаг
a0 = (0, 0)		# w0, w1
h = 0.1

# Находим все координаты градиентного спуска
point = a0
points = (a0,)
for _ in range(2):
	ldf_w1 = lambdify((w0, w1), expr=df_w1)(w0=point[0], w1=point[1])
	ldf_w0 = lambdify((w0, w1), expr=df_w0)(w0=point[0], w1=point[1])
	point = point[0] - h * ldf_w0, point[1] - h * ldf_w1
	points += point,
	if abs(ldf_w0) < 0.008 > abs(ldf_w1):
		break


print(*points, '\n', sep='\n')
w0_optim, w1_optim = point							# Сохраним оптимальные веса для предсказания новых данных
print(f'w0_optim = {w0_optim}, w1_optim = {w1_optim}')


# ------------------------------- 2й  вид  Регуляризации  (L1 - регуляризация) -------------------------------
# В хвост функции потерь добавляем сумму модулей весов помноженную на константу
#  C * (|w1| + |w0|)
# C - это Константа (чем больше С, тем больше вероятность, что веса будут равны 0)

# Определяем символьные переменные
w1, w0 = symbols('w1 w0', real=True)

# входные и целевые данные ТВ
x_val, y_val = [0, 1, 2], [1, 2, 3]

# У нас простейшая НС. один аргумент на входе и по одному w1, w0, один нейрон
# Запишем функцию активации, функцию НС и Функцию Потерь
R = lambda elem: elem
F = lambda x: x * w1 + w0
C = 1
F_w = sum((R(F(x)) - y) ** 2 for x, y in zip(x_val, y_val)) + C * (abs(w1) + abs(w0))

# Дальше всё одинаково
